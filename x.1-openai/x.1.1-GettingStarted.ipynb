{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T22:14:58.468022Z",
     "start_time": "2025-11-25T22:14:58.442775Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T22:14:59.991861Z",
     "start_time": "2025-11-25T22:14:59.984856Z"
    }
   },
   "cell_type": "code",
   "source": "os.environ[\"LANGCHAIN_TRACING_V2\"]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'false'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T22:15:01.206203Z",
     "start_time": "2025-11-25T22:15:01.192205Z"
    }
   },
   "cell_type": "code",
   "source": "os.environ[\"LANGCHAIN_PROJECT\"]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GenAIAppWithOpenAi'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T22:15:17.407349Z",
     "start_time": "2025-11-25T22:15:13.734016Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-5-mini\")\n",
    "print(llm)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utkar\\Documents\\Code\\Langchain\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x0000023EDEB1B9D0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000023EDEBB0280> root_client=<openai.OpenAI object at 0x0000023EDEB1B760> root_async_client=<openai.AsyncOpenAI object at 0x0000023EDF179D50> model_name='gpt-5-mini' model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://embedding-model-ai.openai.azure.com/openai/v1/'\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T22:15:36.475153Z",
     "start_time": "2025-11-25T22:15:22.537498Z"
    }
   },
   "source": [
    "## Input and get response form LLM\n",
    "\n",
    "result=llm.invoke(\"What is generative AI?\")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T22:16:06.965084Z",
     "start_time": "2025-11-25T22:16:06.948085Z"
    }
   },
   "source": [
    "print(result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a class of artificial intelligence systems designed to create new content — text, images, audio, video, code, or other data — that resembles the examples they were trained on. Instead of only classifying or predicting labels, these models generate original outputs.\\n\\nKey ideas in plain language\\n- What it does: Produces new content (writes emails, makes images, composes music, writes code).\\n- How it learns: Trained on large datasets to predict or reconstruct data — e.g., next word prediction or restoring noisy images — which teaches patterns, styles, and structure.\\n- Common architectures: Transformers (e.g., GPT-family) for text and multimodal tasks, diffusion models (e.g., Stable Diffusion) for images, GANs and VAEs historically for images and other data types.\\n\\nExamples and tools\\n- Text: ChatGPT, Claude — generate articles, summaries, answers.\\n- Images: DALL·E, Midjourney, Stable Diffusion — generate pictures from prompts.\\n- Audio: Tools that synthesize speech or music.\\n- Code: Models that generate programming code (Copilot, Codegen).\\n\\nStrengths\\n- Fast generation at scale.\\n- Can produce creative or novel combinations.\\n- Useful for drafting, prototyping, personalization, data augmentation, and automation.\\n\\nLimitations and risks\\n- Hallucinations: can state false facts confidently.\\n- Bias and fairness: inherit biases from training data.\\n- Copyright and ownership: may reproduce or closely mimic copyrighted material.\\n- Misuse potential: deepfakes, disinformation, automated scams.\\n- Lack of true understanding: models are pattern predictors, not conscious reasoners.\\n\\nPractical safety and reliability tips\\n- Verify critical outputs with trusted sources.\\n- Use human review for sensitive decisions.\\n- Apply guardrails: content filters, provenance/tracing, retrieval-augmented generation (link answers to sources).\\n- Be careful with private or sensitive data during prompts.\\n\\nWhy it matters\\nGenerative AI is changing how people create content and automate tasks, boosting productivity and enabling new creative workflows — while raising important technical, legal, and ethical questions that organizations and users must manage.\\n\\nIf you want, I can show short examples (text prompt → output), compare major models, or explain how to prompt these systems effectively.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 728, 'prompt_tokens': 12, 'total_tokens': 740, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 256, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CfvbfcXR3tYYtyRjnjvuyKsxycTWv', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--bd90c080-19ec-4aa0-b73b-3288357cdef4-0' usage_metadata={'input_tokens': 12, 'output_tokens': 728, 'total_tokens': 740, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 256}}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T22:13:16.518905Z",
     "start_time": "2025-11-24T22:13:16.378537Z"
    }
   },
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T22:17:11.187148Z",
     "start_time": "2025-11-24T22:16:40.766997Z"
    }
   },
   "source": [
    "## chain \n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Short answer\\n- LangSmith is an observability, debugging, and evaluation platform for building production LLM applications. It was created to help you trace, inspect, compare, and evaluate runs (calls) of prompts, chains, agents, and models so you can debug, optimize, and monitor LLM apps faster.\\n\\nWhat it does (high level)\\n- Tracing & debugging: capture detailed run traces (calls, nested steps, inputs/outputs, tokens, timings, errors) and visualize execution trees and timelines so you can find where logic or hallucinations occur.\\n- Evaluation & datasets: create evaluation datasets, run automated evaluations (quality/metrics), and label or score outputs to benchmark prompts and models.\\n- Comparison & analysis: compare runs, models, or prompt versions side-by-side; track latency, cost, and quality metrics.\\n- Integrations & SDKs: integrates with LangChain (tight integration), common LLM providers, and exposes SDKs/APIs for instrumenting code (Python/JS and REST-based ingestion).\\n- Replay & reproduction: reproduce flows with captured inputs and metadata to iterate quickly.\\n\\nCore concepts\\n- Run / Trace: a single execution (LLM call, agent run, chain step) including nested steps and events.\\n- Event / Step: the atoms of a trace — prompts, LLM responses, tool calls, errors.\\n- Dataset: a collection of examples you can use for evaluations and labeling.\\n- Evaluation: metrics, scoring functions, or human labels applied to a dataset to measure model behavior.\\n- Artifacts / Metadata: saved inputs, outputs, logs, and extra context attached to runs.\\n\\nTypical use cases\\n- Find and diagnose where agents or chains fail or hallucinate.\\n- Compare different models or prompt variants to choose the best one.\\n- Build continuous evaluation suites to detect regressions when changing code or model.\\n- Collect labeled examples and human feedback to improve prompts or fine-tuning.\\n- Monitor production LLM calls (latency, costs, error rates).\\n\\nHow to get started (high-level)\\n1. Sign up for LangSmith (or enable LangSmith in your LangChain account).\\n2. Install the SDK or use the LangChain integration.\\n3. Add minimal instrumentation (the SDK or LangChain integration will capture runs automatically in most cases).\\n4. Run your app and view runs, traces, datasets, and evaluations in the LangSmith UI.\\n5. Create evaluations and use comparisons or filters to iterate on prompts/models.\\n\\nExample (conceptual)\\n- Instrumentation is typically a few lines in your app (or enabled automatically when using LangChain). A conceptual flow:\\n  - Configure API key and client.\\n  - Run an LLM/agent with tracing enabled.\\n  - Inspect the run in the LangSmith UI to see the call tree, tokens, and outputs.\\n  - Create an evaluation dataset and run automated metrics to compare model versions.\\n\\nPrivacy, hosting & pricing\\n- LangSmith is offered as a hosted SaaS with free and paid tiers and enterprise options. Data retention, privacy controls, and enterprise features vary by plan — check the official docs or sales team for details and on-prem/enterprise options.\\n\\nAlternatives & complementing tools\\n- Alternatives/adjacent tools include experiment and trace tools such as Weights & Biases, Comet, or custom logging + dashboards. For evaluation specifically, OpenAI Evals and other eval harnesses can complement LangSmith.\\n\\nWhere to learn more\\n- See the official LangSmith documentation and the LangChain docs for SDK examples, tutorials, and integration guides.\\n\\nIf you want, I can:\\n- Walk you through instrumenting a sample Python or JavaScript app.\\n- Help design an evaluation dataset and metrics for your use case.\\n- Show a concrete snippet for your exact stack (LangChain agent, direct LLM calls, etc.).' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 2125, 'prompt_tokens': 32, 'total_tokens': 2157, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1344, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CfZ9OrwhCnW0vH3sPTJArAutTYqvd', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--f1e1acda-d88b-4600-9661-663d3355c437-0' usage_metadata={'input_tokens': 32, 'output_tokens': 2125, 'total_tokens': 2157, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1344}}\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T22:18:49.569481Z",
     "start_time": "2025-11-24T22:18:49.549479Z"
    }
   },
   "source": [
    "type(response)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T22:28:10.474794Z",
     "start_time": "2025-11-24T22:27:42.933021Z"
    }
   },
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short answer\n",
      "LangSmith is a product from the LangChain ecosystem for building, observing, debugging, and evaluating LLM/agent-driven applications. It gives you a place to collect and inspect runs (prompts, model outputs, tool calls), run automated evaluations and comparisons across models or prompts, and share traces with teammates.\n",
      "\n",
      "What it does (core concepts)\n",
      "- Run tracing: captures each invocation (a “run”) of an LLM or agent, including inputs, outputs, tool calls, metadata, and nested/child runs.\n",
      "- Visualization: a web UI to view execution traces, step-by-step outputs, chain/agent flows, tokens / costs, and artifacts (files, saved responses).\n",
      "- Evaluation & benchmarking: create evaluation datasets, run model comparisons, compute custom metrics, and track performance over time.\n",
      "- Instrumentation: SDKs and integrations let you automatically capture traces from LangChain chains, agents, or custom code.\n",
      "- Collaboration & organization: workspaces/projects, tagging, filtering, and sharing traces with teammates.\n",
      "- Monitoring & observability: alerting/metrics and historical views for model behavior, prompt regressions, or error spikes.\n",
      "\n",
      "Typical use cases\n",
      "- Prompt engineering and iterative debugging of chains/agents.\n",
      "- Reproducing and diagnosing failures (why did an agent call the wrong tool?).\n",
      "- Comparing multiple models or prompt variants on a benchmark dataset.\n",
      "- Tracking regressions after model / prompt changes.\n",
      "- Sharing examples and decision traces with product, QA, or compliance teams.\n",
      "\n",
      "How it works (high level)\n",
      "- You sign up for LangSmith (or enable it from LangChain), get an API key, and install the SDK.\n",
      "- Instrument your code (or enable automatic tracing in LangChain). Each LLM or agent action becomes a structured “run” that is sent to LangSmith.\n",
      "- The UI organizes runs by session/project and lets you inspect steps, metadata, tokens, durations, and any attached artifacts.\n",
      "- You can create evaluation jobs against datasets to get metrics and comparisons across models or prompt settings.\n",
      "\n",
      "Integrations and SDKs\n",
      "- Deep integration with LangChain (so if you’re using LangChain chains/agents, enabling LangSmith tracing is straightforward).\n",
      "- Works with many LLM providers (OpenAI, Anthropic, Azure OpenAI, etc.) because it collects the inputs/outputs, not the model internals.\n",
      "- SDKs / API: typically there are Python and JavaScript SDKs plus a REST API and CLI for automating uploads, running evaluations, or querying metadata.\n",
      "\n",
      "Getting started (quick steps)\n",
      "1. Create an account and get an API key.\n",
      "2. Install the SDK (pip/npm) or enable LangSmith tracing in your LangChain config.\n",
      "3. Set your API key in an environment variable (the docs show the exact name).\n",
      "4. Run your app and inspect runs in the LangSmith web UI.\n",
      "5. Create an evaluation dataset in the UI or via SDK and run model comparisons.\n",
      "\n",
      "Example (conceptual pseudo-code)\n",
      "- Install and configure the SDK, then instrument runs:\n",
      "\n",
      "  # Pseudocode (actual SDK names/args vary; see docs)\n",
      "  from langsmith import Client\n",
      "  client = Client(api_key=\"YOUR_KEY\")\n",
      "  run = client.start_run(name=\"greeting-test\")\n",
      "  run.log_input({\"prompt\": \"Say hi to Alice\"})\n",
      "  output = llm.generate(\"Say hi to Alice\")\n",
      "  run.log_output({\"text\": output})\n",
      "  run.finish()\n",
      "\n",
      "- With LangChain, you typically enable tracing and it will automatically send runs for each chain/agent step to LangSmith.\n",
      "\n",
      "Best practices\n",
      "- Log relevant metadata and tags (model name, temperature, dataset id) so you can filter and compare.\n",
      "- Use evaluation datasets and baseline comparisons to track regressions.\n",
      "- Keep sensitive data handling in mind: redact or not log PII if required by policy or compliance.\n",
      "- Use traces to extract failing examples and create regression tests.\n",
      "\n",
      "Security, pricing, and retention\n",
      "- LangSmith provides enterprise features (SSO, retention controls, data encryption) in paid tiers; free tiers are commonly available for experimentation. Check the provider docs for the exact offerings and compliance details.\n",
      "\n",
      "Where to learn more\n",
      "- Check the LangChain / LangSmith documentation and the LangChain blog for quickstart guides, SDK reference, and examples.\n",
      "- Look up “LangSmith” in LangChain’s docs or the LangChain Labs announcements for the latest tutorials and API docs.\n",
      "\n",
      "If you want, I can:\n",
      "- Show a concrete example with the exact Python/JS calls (I’ll pull the up-to-date SDK method names if you want).\n",
      "- Walk through how to enable automatic tracing in a LangChain agent.\n",
      "- Suggest how to structure metadata and tags for an evaluation workflow. Which would you like next?\n"
     ]
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
