{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Gen AI APP Using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T01:41:23.319124Z",
     "start_time": "2025-11-25T01:41:23.297180Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T22:58:27.649090Z",
     "start_time": "2025-11-24T22:58:27.632018Z"
    }
   },
   "source": [
    "## Data Ingestion--From the website we need to scrape the data\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T23:12:51.860468Z",
     "start_time": "2025-11-24T23:12:51.852468Z"
    }
   },
   "source": [
    "loader=WebBaseLoader(\"https://blog.langchain.com/langchain-langgraph-1dot0/\")\n",
    "loader"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.web_base.WebBaseLoader at 0x2cd5d19c730>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T23:12:55.432770Z",
     "start_time": "2025-11-24T23:12:54.497349Z"
    }
   },
   "source": [
    "docs=loader.load()\n",
    "docs"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}, page_content='\\n\\n\\nLangChain and LangGraph Agent Frameworks Reach v1.0 Milestones\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCase Studies\\n\\n\\n\\n\\nIn the Loop\\n\\n\\n\\n\\nLangChain\\n\\n\\n\\n\\nDocs\\n\\n\\n\\n\\nChangelog\\n\\n\\n\\n\\n\\nSign in\\nSubscribe\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLangChain and LangGraph Agent Frameworks Reach v1.0 Milestones\\n\\n7 min read\\nOct 22, 2025\\n\\n\\n\\n\\n\\nBy Sydney Runkle and the LangChain OSS team We\\'re releasing LangChain 1.0 and LangGraph 1.0 — our first major versions of our open source frameworks! After years of feedback, we\\'ve updated langchain to focus on the core agent loop, provide flexibility with a new concept of middleware, and upgrade model integrations with the latest content types.These two frameworks serve different purposes:LangChain is the fastest way to build an AI agent — with a standard tool calling architecture, provider agnostic design, and middleware for customization.LangGraph is a lower level framework and runtime, useful for highly custom and controllable agents, designed to support production-grade, long running agentsThese 1.0 releases mark our commitment to stability for our open source libraries and no breaking changes until 2.0. Alongside these releases, we\\'re launching a completely redesigned docs site.Learn more about the changes below, and check our behind-the-scenes conversation with our engineers for more commentary.LangChain 1.0LangChain has always offered high-level interfaces for interacting with LLMs and building agents. With standardized model abstractions and prebuilt agent patterns, it helps developers ship AI features fast and build sophisticated applications without vendor lock-in. This is essential in a space where the best model for any given task changes regularly.We\\'ve been listening. Over the past three years, we\\'ve heard consistent feedback: LangChain\\'s abstractions were sometimes too heavy, the package surface area had grown unwieldy, and developers wanted more control over the agent loop without dropping down to raw LLM calls. Some struggled with customization when their use cases diverged from our prebuilt patterns. We took this feedback seriously. LangChain 1.0 is our response— a thoughtful refinement that preserves what works while fixing what didn\\'t.\"We rely heavily on the durable runtime that LangGraph provides under the hood to support our agent developments, and the new agent prebuilt and middleware in LangChain 1.0 makes it far more flexible than before. We\\'re excited about 1.0 and are already building with the new features at Rippling.\" – Ankur Bhatt, Head of AI at RipplingWe’re leaning hard into three things for LangChain 1.0:Our new create_agent abstraction: the fastest way to build an agent with any model providerBuilt on the LangGraph runtime, helping to power reliable agentsPrebuilt and user defined middleware enable step by step control and customizationStandard content blocks: a provider agnostic spec for model outputs.Streamlined surface area: we’re trimming down our namespace to focus on what developers use to build agents.1. create_agentThe create_agent abstraction is built around the core agent loop, making it easy to get started quickly. Here\\'s how the loop works:Setup: select a model and give it some tools and a prompt.Execution:Send a request to the modelThe model responds with either:Tool calls → execute the tool and add results to the conversationFinal answer → return the resultRepeat from step 1The new create_agent function uses LangGraph under the hood to run this loop. It has a very similar feel to the create_react_agent function from langgraph.prebuilts, which has been used in production for a year.Getting started with an agent in langchain is easy:from langchain.agents import create_agent\\n\\nweather_agent = create_agent(\\n    model=\"openai:gpt-5\",\\n    tools=[get_weather],\\n    system_prompt=\"Help the user by fetching the weather in their city.\",\\n)\\n\\nresult = agent.invoke({\"role\": \"user\", \"what\\'s the weather in SF?\"})\\nMost agent builders are highly restrictive in that they don’t permit customization outside of this core loop. That’s where create_agent stands out with our introduction of middleware.Middleware:Middleware defines a set of hooks that allow you to customize behavior in the agent loop, enabling fine grained control at every step an agent takes.We’re including a few built-in middlewares for common use cases:Human-in-the-loop: Pause agent execution to let users approve, edit, or reject tool calls before they execute. This is essential for agents that interact with external systems, send communications, or make sensitive transactions.Summarization: Condense message history when it approaches context limits, keeping recent messages intact while summarizing older context. This prevents token overflow errors and keeps long-running agent sessions performant.PII redaction: Use pattern matching to identify and redact sensitive information like email addresses, phone numbers, and social security numbers before content is passed to the model. This helps maintain compliance with privacy regulations and prevents accidental exposure of user data.LangChain also supports custom middleware that hook into various of points in the agent loop. The following diagram showcases these hooks:Structured Output Generation:We’ve also improved structured output generation in the agent loop by incorporating it into the main model <–> tools loop. This reduces both latency and cost by eliminating an extra LLM call that used to happen in addition to the main loop.Developers now have fine grained control over how structured output is generated, either via tool calling or provider-native structured output.from langchain.agents import create_agent\\nfrom langchain.agents.structured_output import ToolStrategy\\n\\nfrom pydantic import BaseModel\\n\\nclass WeatherReport(BaseModel):\\n    temperature: float    \\n    condition: str\\n\\nagent = create_agent(\\n    \"openai:gpt-4o-mini\",\\n    tools=[weather_tool],\\n    response_format=ToolStrategy(WeatherReport),\\n    prompt=\"Help the user by fetching the weather in their city.\",\\n)\\nStandard Content BlocksLangChain’s hundreds of provider integrations (OpenAI, Anthropic, etc.) are largely unchanged in 1.0. The interfaces used by these abstractions live in langchain-core, which we’re promoting to 1.0 with one key addition: standardized content blocks.Much of LangChain’s value comes from its provider-agnostic interfaces, allowing developers to use a common protocol across multiple providers in a single application. Without standard content blocks, switching models or providers often breaks streams, UIs and frontends, and memory stores. The new .content_blocks property on messages provides:Consistent content types across providersSupport for reasoning traces, citations, and tool calls – including server-side tool callsTyped interfaces for complex response structuresFull backward compatibilityThis keeps LangChain’s abstractions current with modern LLM capabilities like reasoning, citations, and server side tool execution, while minimizing breaking changes.Simplifying the packageLangChain 1.0 reduces package scope to essential abstractions. Legacy functionality moves to langchain-classic for backwards compatibility. As the framework has matured, we\\'ve learned what patterns matter most. This streamlined package cuts through years of accumulated features to make LangChain simple and powerful.Key Changes:create_agent introduced in LangChain, with create_react_agent deprecated in langgraph.prebuiltPython 3.9 support dropped due to October 2025 EOL, v1.0 requires Python 3.10+Python 3.14 support is coming soon!Package surface area reduced to focus on core abstractions with old functionality moved to langchain-classic Installation# Python\\nuv pip install --upgrade langchain\\nuv pip install langchain-classic\\n\\n# JavaScript\\nnpm install @langchain/langchain@latest\\nnpm install @langchain/langchain-classic\\nMigrationIf you\\'re upgrading from a previous version of LangChain, we\\'ve created detailed resources to guide you through the changes.Release overviews: Python, JavaScriptMigration guides: Python, JavaScriptLangGraph 1.0AI agents are moving from prototype to production, but core features like persistence, observability, and human-in-the-loop control have remained underserved.LangGraph 1.0 addresses these gaps with a powerful graph-based execution model, and it provides production-ready features for reliable agentic systems:Durable state - Your agent\\'s execution state persists automatically, so if your server restarts mid-conversation or a long-running workflow gets interrupted, it picks up exactly where it left off without losing context or forcing users to start over.Built-in persistence - Save and resume agent workflows at any point without writing custom database logic, enabling use cases like multi-day approval processes or background jobs that run across multiple sessions.Human-in-the-loop patterns - Pause agent execution for human review, modification, or approval with first-class API support, making it trivial to build systems where humans stay in control of high-stakes decisions.For a deeper dive into our design philosophy, check out our blog post on building LangGraph from first principles.This is the first stable major release in the durable agent framework space — a major milestone for production-ready AI systems. After more than a year of iteration and widespread adoption by companies like Uber, LinkedIn, and Klarna, LangGraph is officially v1.Breaking Changes & MigrationThe only notable change is deprecation of the langgraph.prebuilt module, with enhanced functionality moved to langchain.agents.LangGraph 1.0 maintains full backward compatibility.Installation# Python\\nuv pip install --upgrade langgraph\\n\\n# JavaScript\\nnpm install @langchain/langgraph@latest\\nWhen to Use Each FrameworkLangChain lets you build and ship agents fast with high-level abstractions for common patterns, while LangGraph gives you fine-grained control for complex workflows that require customization.The best part? LangChain agents are built on LangGraph, so you\\'re not locked in. Start with LangChain\\'s high-level APIs and seamlessly drop down to LangGraph when you need more control. Since graphs are composable, you can mix both approaches—using agents created with create_agent inside custom LangGraph workflows as your needs evolve.Choose LangChain 1.0 for:Shipping quickly with standard agent patternsAgents that fit the default loop (model → tools → response)Middleware-based customizationHigher-level abstractions over low-level controlChoose LangGraph 1.0 for:Workflows with a mixture of deterministic and agentic componentsLong running business process automationSensitive workflows which necessitate more oversight / human in the loopHighly custom or complex workflowsApplications where latency and / or cost need to be carefully controlledDocumentation & ResourcesWe\\'re launching a much improved documentation site at docs.langchain.com. For the first time, all LangChain and LangGraph docs—across Python and JavaScript—live in one unified site with parallel examples, shared conceptual guides, and consolidated API references.The new docs feature more intuitive navigation, thoughtful guides, and in depth tutorials for common agent architectures.Thank You & FeedbackWe hope you love these 1.0 releases. We are incredibly grateful for the community that has pressure tested LangChain and LangGraph over the years to make them what they are today. With 90M monthly downloads and powering production applications at Uber, JP Morgan, Blackrock, Cisco, and more, we have a duty to you all to keep innovating but also be the most dependable framework for building agents. While this is a major milestone, we are still at the beginning of a major change in software. We want to hear from you: post on the LangChain Forum and tell us what you think of our 1.0 release and what you\\'re building.\\n\\n\\nJoin our newsletter\\nUpdates from the LangChain team and community\\n\\n\\nEnter your email\\n\\nSubscribe\\n\\nProcessing your application...\\nSuccess! Please check your inbox and click the link to confirm your subscription.\\nSorry, something went wrong. Please try again.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSign up\\n\\n\\n\\n\\n\\n            © LangChain Blog 2025\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T23:12:59.419287Z",
     "start_time": "2025-11-24T23:12:59.410285Z"
    }
   },
   "source": [
    "### Load Data--> Docs-->Divide our Docuemnts into chunks dcouments-->text-->vectors-->Vector Embeddings--->Vector Store DB\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "documents=text_splitter.split_documents(docs)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T23:13:01.791309Z",
     "start_time": "2025-11-24T23:13:01.777306Z"
    }
   },
   "source": [
    "for docs in documents:\n",
    "    print(f'{docs}==========END===========')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Case Studies\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "In the Loop\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LangChain\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Changelog\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sign in\n",
      "Subscribe\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones\n",
      "\n",
      "7 min read\n",
      "Oct 22, 2025' metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}==========END===========\n",
      "page_content='By Sydney Runkle and the LangChain OSS team We're releasing LangChain 1.0 and LangGraph 1.0 — our first major versions of our open source frameworks! After years of feedback, we've updated langchain to focus on the core agent loop, provide flexibility with a new concept of middleware, and upgrade model integrations with the latest content types.These two frameworks serve different purposes:LangChain is the fastest way to build an AI agent — with a standard tool calling architecture, provider agnostic design, and middleware for customization.LangGraph is a lower level framework and runtime, useful for highly custom and controllable agents, designed to support production-grade, long running agentsThese 1.0 releases mark our commitment to stability for our open source libraries and no breaking changes until 2.0. Alongside these releases, we're launching a completely redesigned docs site.Learn more about the changes below, and check our behind-the-scenes conversation with our engineers' metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}==========END===========\n",
      "page_content='changes until 2.0. Alongside these releases, we're launching a completely redesigned docs site.Learn more about the changes below, and check our behind-the-scenes conversation with our engineers for more commentary.LangChain 1.0LangChain has always offered high-level interfaces for interacting with LLMs and building agents. With standardized model abstractions and prebuilt agent patterns, it helps developers ship AI features fast and build sophisticated applications without vendor lock-in. This is essential in a space where the best model for any given task changes regularly.We've been listening. Over the past three years, we've heard consistent feedback: LangChain's abstractions were sometimes too heavy, the package surface area had grown unwieldy, and developers wanted more control over the agent loop without dropping down to raw LLM calls. Some struggled with customization when their use cases diverged from our prebuilt patterns. We took this feedback seriously. LangChain 1.0 is' metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}==========END===========\n",
      "page_content='the agent loop without dropping down to raw LLM calls. Some struggled with customization when their use cases diverged from our prebuilt patterns. We took this feedback seriously. LangChain 1.0 is our response— a thoughtful refinement that preserves what works while fixing what didn't.\"We rely heavily on the durable runtime that LangGraph provides under the hood to support our agent developments, and the new agent prebuilt and middleware in LangChain 1.0 makes it far more flexible than before. We're excited about 1.0 and are already building with the new features at Rippling.\" – Ankur Bhatt, Head of AI at RipplingWe’re leaning hard into three things for LangChain 1.0:Our new create_agent abstraction: the fastest way to build an agent with any model providerBuilt on the LangGraph runtime, helping to power reliable agentsPrebuilt and user defined middleware enable step by step control and customizationStandard content blocks: a provider agnostic spec for model outputs.Streamlined' metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}==========END===========\n",
      "page_content='helping to power reliable agentsPrebuilt and user defined middleware enable step by step control and customizationStandard content blocks: a provider agnostic spec for model outputs.Streamlined surface area: we’re trimming down our namespace to focus on what developers use to build agents.1. create_agentThe create_agent abstraction is built around the core agent loop, making it easy to get started quickly. Here's how the loop works:Setup: select a model and give it some tools and a prompt.Execution:Send a request to the modelThe model responds with either:Tool calls → execute the tool and add results to the conversationFinal answer → return the resultRepeat from step 1The new create_agent function uses LangGraph under the hood to run this loop. It has a very similar feel to the create_react_agent function from langgraph.prebuilts, which has been used in production for a year.Getting started with an agent in langchain is easy:from langchain.agents import create_agent' metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}==========END===========\n",
      "page_content='weather_agent = create_agent(\n",
      "    model=\"openai:gpt-5\",\n",
      "    tools=[get_weather],\n",
      "    system_prompt=\"Help the user by fetching the weather in their city.\",\n",
      ")' metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}==========END===========\n",
      "page_content='result = agent.invoke({\"role\": \"user\", \"what's the weather in SF?\"})' metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}==========END===========\n",
      "page_content='Most agent builders are highly restrictive in that they don’t permit customization outside of this core loop. That’s where create_agent stands out with our introduction of middleware.Middleware:Middleware defines a set of hooks that allow you to customize behavior in the agent loop, enabling fine grained control at every step an agent takes.We’re including a few built-in middlewares for common use cases:Human-in-the-loop: Pause agent execution to let users approve, edit, or reject tool calls before they execute. This is essential for agents that interact with external systems, send communications, or make sensitive transactions.Summarization: Condense message history when it approaches context limits, keeping recent messages intact while summarizing older context. This prevents token overflow errors and keeps long-running agent sessions performant.PII redaction: Use pattern matching to identify and redact sensitive information like email addresses, phone numbers, and social security' metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}==========END===========\n",
      "page_content='errors and keeps long-running agent sessions performant.PII redaction: Use pattern matching to identify and redact sensitive information like email addresses, phone numbers, and social security numbers before content is passed to the model. This helps maintain compliance with privacy regulations and prevents accidental exposure of user data.LangChain also supports custom middleware that hook into various of points in the agent loop. The following diagram showcases these hooks:Structured Output Generation:We’ve also improved structured output generation in the agent loop by incorporating it into the main model <–> tools loop. This reduces both latency and cost by eliminating an extra LLM call that used to happen in addition to the main loop.Developers now have fine grained control over how structured output is generated, either via tool calling or provider-native structured output.from langchain.agents import create_agent' metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}==========END===========\n",
      "page_content='from langchain.agents.structured_output import ToolStrategy' metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}==========END===========\n",
      "page_content='from pydantic import BaseModel\n",
      "\n",
      "class WeatherReport(BaseModel):\n",
      "    temperature: float    \n",
      "    condition: str' metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}==========END===========\n",
      "page_content='agent = create_agent(\n",
      "    \"openai:gpt-4o-mini\",\n",
      "    tools=[weather_tool],\n",
      "    response_format=ToolStrategy(WeatherReport),\n",
      "    prompt=\"Help the user by fetching the weather in their city.\",\n",
      ")' metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}==========END===========\n",
      "page_content='Standard Content BlocksLangChain’s hundreds of provider integrations (OpenAI, Anthropic, etc.) are largely unchanged in 1.0. The interfaces used by these abstractions live in langchain-core, which we’re promoting to 1.0 with one key addition: standardized content blocks.Much of LangChain’s value comes from its provider-agnostic interfaces, allowing developers to use a common protocol across multiple providers in a single application. Without standard content blocks, switching models or providers often breaks streams, UIs and frontends, and memory stores. The new .content_blocks property on messages provides:Consistent content types across providersSupport for reasoning traces, citations, and tool calls – including server-side tool callsTyped interfaces for complex response structuresFull backward compatibilityThis keeps LangChain’s abstractions current with modern LLM capabilities like reasoning, citations, and server side tool execution, while minimizing breaking changes.Simplifying' metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}==========END===========\n",
      "page_content='backward compatibilityThis keeps LangChain’s abstractions current with modern LLM capabilities like reasoning, citations, and server side tool execution, while minimizing breaking changes.Simplifying the packageLangChain 1.0 reduces package scope to essential abstractions. Legacy functionality moves to langchain-classic for backwards compatibility. As the framework has matured, we've learned what patterns matter most. This streamlined package cuts through years of accumulated features to make LangChain simple and powerful.Key Changes:create_agent introduced in LangChain, with create_react_agent deprecated in langgraph.prebuiltPython 3.9 support dropped due to October 2025 EOL, v1.0 requires Python 3.10+Python 3.14 support is coming soon!Package surface area reduced to focus on core abstractions with old functionality moved to langchain-classic Installation# Python' metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}==========END===========\n",
      "page_content='uv pip install --upgrade langchain\n",
      "uv pip install langchain-classic' metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}==========END===========\n",
      "page_content='# JavaScript\n",
      "npm install @langchain/langchain@latest\n",
      "npm install @langchain/langchain-classic' metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}==========END===========\n",
      "page_content='MigrationIf you're upgrading from a previous version of LangChain, we've created detailed resources to guide you through the changes.Release overviews: Python, JavaScriptMigration guides: Python, JavaScriptLangGraph 1.0AI agents are moving from prototype to production, but core features like persistence, observability, and human-in-the-loop control have remained underserved.LangGraph 1.0 addresses these gaps with a powerful graph-based execution model, and it provides production-ready features for reliable agentic systems:Durable state - Your agent's execution state persists automatically, so if your server restarts mid-conversation or a long-running workflow gets interrupted, it picks up exactly where it left off without losing context or forcing users to start over.Built-in persistence - Save and resume agent workflows at any point without writing custom database logic, enabling use cases like multi-day approval processes or background jobs that run across multiple' metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}==========END===========\n",
      "page_content='persistence - Save and resume agent workflows at any point without writing custom database logic, enabling use cases like multi-day approval processes or background jobs that run across multiple sessions.Human-in-the-loop patterns - Pause agent execution for human review, modification, or approval with first-class API support, making it trivial to build systems where humans stay in control of high-stakes decisions.For a deeper dive into our design philosophy, check out our blog post on building LangGraph from first principles.This is the first stable major release in the durable agent framework space — a major milestone for production-ready AI systems. After more than a year of iteration and widespread adoption by companies like Uber, LinkedIn, and Klarna, LangGraph is officially v1.Breaking Changes & MigrationThe only notable change is deprecation of the langgraph.prebuilt module, with enhanced functionality moved to langchain.agents.LangGraph 1.0 maintains full backward' metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}==========END===========\n",
      "page_content='v1.Breaking Changes & MigrationThe only notable change is deprecation of the langgraph.prebuilt module, with enhanced functionality moved to langchain.agents.LangGraph 1.0 maintains full backward compatibility.Installation# Python' metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}==========END===========\n",
      "page_content='uv pip install --upgrade langgraph' metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}==========END===========\n",
      "page_content='# JavaScript\n",
      "npm install @langchain/langgraph@latest' metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}==========END===========\n",
      "page_content='When to Use Each FrameworkLangChain lets you build and ship agents fast with high-level abstractions for common patterns, while LangGraph gives you fine-grained control for complex workflows that require customization.The best part? LangChain agents are built on LangGraph, so you're not locked in. Start with LangChain's high-level APIs and seamlessly drop down to LangGraph when you need more control. Since graphs are composable, you can mix both approaches—using agents created with create_agent inside custom LangGraph workflows as your needs evolve.Choose LangChain 1.0 for:Shipping quickly with standard agent patternsAgents that fit the default loop (model → tools → response)Middleware-based customizationHigher-level abstractions over low-level controlChoose LangGraph 1.0 for:Workflows with a mixture of deterministic and agentic componentsLong running business process automationSensitive workflows which necessitate more oversight / human in the loopHighly custom or complex' metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}==========END===========\n",
      "page_content='with a mixture of deterministic and agentic componentsLong running business process automationSensitive workflows which necessitate more oversight / human in the loopHighly custom or complex workflowsApplications where latency and / or cost need to be carefully controlledDocumentation & ResourcesWe're launching a much improved documentation site at docs.langchain.com. For the first time, all LangChain and LangGraph docs—across Python and JavaScript—live in one unified site with parallel examples, shared conceptual guides, and consolidated API references.The new docs feature more intuitive navigation, thoughtful guides, and in depth tutorials for common agent architectures.Thank You & FeedbackWe hope you love these 1.0 releases. We are incredibly grateful for the community that has pressure tested LangChain and LangGraph over the years to make them what they are today. With 90M monthly downloads and powering production applications at Uber, JP Morgan, Blackrock, Cisco, and more, we' metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}==========END===========\n",
      "page_content='tested LangChain and LangGraph over the years to make them what they are today. With 90M monthly downloads and powering production applications at Uber, JP Morgan, Blackrock, Cisco, and more, we have a duty to you all to keep innovating but also be the most dependable framework for building agents. While this is a major milestone, we are still at the beginning of a major change in software. We want to hear from you: post on the LangChain Forum and tell us what you think of our 1.0 release and what you're building.' metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}==========END===========\n",
      "page_content='Join our newsletter\n",
      "Updates from the LangChain team and community\n",
      "\n",
      "\n",
      "Enter your email\n",
      "\n",
      "Subscribe\n",
      "\n",
      "Processing your application...\n",
      "Success! Please check your inbox and click the link to confirm your subscription.\n",
      "Sorry, something went wrong. Please try again.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sign up\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            © LangChain Blog 2025' metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}==========END===========\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T23:42:50.215586Z",
     "start_time": "2025-11-24T23:42:49.741658Z"
    }
   },
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T23:42:53.121942Z",
     "start_time": "2025-11-24T23:42:51.327215Z"
    }
   },
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "vectorstoredb=FAISS.from_documents(documents,embeddings)"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T23:43:24.583532Z",
     "start_time": "2025-11-24T23:43:24.575532Z"
    }
   },
   "source": [
    "vectorstoredb"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x2cd52982260>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T01:03:49.642378Z",
     "start_time": "2025-11-25T01:03:48.574843Z"
    }
   },
   "source": [
    "## Query From a vector db\n",
    "query=\"LangChain is the fastest way to build an ?\"\n",
    "result=vectorstoredb.similarity_search(query)\n",
    "result[0].page_content"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"When to Use Each FrameworkLangChain lets you build and ship agents fast with high-level abstractions for common patterns, while LangGraph gives you fine-grained control for complex workflows that require customization.The best part? LangChain agents are built on LangGraph, so you're not locked in. Start with LangChain's high-level APIs and seamlessly drop down to LangGraph when you need more control. Since graphs are composable, you can mix both approaches—using agents created with create_agent inside custom LangGraph workflows as your needs evolve.Choose LangChain 1.0 for:Shipping quickly with standard agent patternsAgents that fit the default loop (model → tools → response)Middleware-based customizationHigher-level abstractions over low-level controlChoose LangGraph 1.0 for:Workflows with a mixture of deterministic and agentic componentsLong running business process automationSensitive workflows which necessitate more oversight / human in the loopHighly custom or complex\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T01:43:15.060560Z",
     "start_time": "2025-11-25T01:43:15.044531Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=os.environ['model'])\n",
    "llm"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000002CD52E743A0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002CD52E74460>, root_client=<openai.OpenAI object at 0x000002CD52E74340>, root_async_client=<openai.AsyncOpenAI object at 0x000002CD52E74850>, model_name='gpt-5-mini', model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://embedding-model-ai.openai.azure.com/openai/v1/')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T01:43:19.920483Z",
     "start_time": "2025-11-25T01:43:19.901514Z"
    }
   },
   "source": [
    "## Retrieval Chain, Document chain\n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Answer the following question based only on the provided context:\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "document_chain=create_stuff_documents_chain(llm,prompt)\n",
    "document_chain"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nAnswer the following question based only on the provided context:\\n<context>\\n{context}\\n</context>\\n\\n\\n'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000002CD52E743A0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002CD52E74460>, root_client=<openai.OpenAI object at 0x000002CD52E74340>, root_async_client=<openai.AsyncOpenAI object at 0x000002CD52E74850>, model_name='gpt-5-mini', model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://embedding-model-ai.openai.azure.com/openai/v1/')\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T01:43:31.949698Z",
     "start_time": "2025-11-25T01:43:25.660144Z"
    }
   },
   "source": [
    "from langchain_core.documents import Document\n",
    "document_chain.invoke({\n",
    "    \"input\":\"LangChain is the fastest way to build an ?\",\n",
    "    \"context\":[Document(page_content=\"When to Use Each FrameworkLangChain lets you build and ship agents fast with high-level abstractions for common patterns, while LangGraph gives you fine-grained control for complex workflows that require customization.The best part? LangChain agents are built on LangGraph, so you're not locked in. Start with LangChain's high-level APIs and seamlessly drop down to LangGraph when you need more control. Since graphs are composable, you can mix both approaches—using agents created with create_agent inside custom LangGraph workflows as your needs evolve.Choose LangChain 1.0 for:Shipping quickly with standard agent patternsAgents that fit the default loop (model → tools → response)Middleware-based customizationHigher-level abstractions over low-level controlChoose LangGraph 1.0 for:Workflows with a mixture of deterministic and agentic componentsLong running business process automationSensitive workflows which necessitate more oversight / human in the loopHighly custom or complex\")]\n",
    "})"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Use LangChain 1.0 when you want to move fast with standard agent patterns and higher-level abstractions:\\n- Shipping quickly with common agent workflows\\n- Agents that fit the default loop (model → tools → response)\\n- Middleware-based customization without low-level control\\n\\nUse LangGraph 1.0 when you need fine-grained control for complex or sensitive workflows:\\n- Workflows mixing deterministic and agentic components\\n- Long-running business process automation\\n- Sensitive processes requiring oversight or human-in-the-loop\\n- Highly custom or complex logic\\n\\nNotes from the context:\\n- LangChain agents are built on LangGraph, so you can start with LangChain and drop into LangGraph when needed.\\n- Graphs are composable, so you can mix both approaches (for example, use agents created with create_agent inside custom LangGraph workflows).'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we want the documents to first come from the retriever we just set up. That way, we can use the retriever to dynamically select the most relevant documents and pass those in for a given question."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T01:44:44.851564Z",
     "start_time": "2025-11-25T01:44:44.833975Z"
    }
   },
   "source": [
    "### Input--->Retriever--->vectorstoredb\n",
    "\n",
    "vectorstoredb"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x2cd52982260>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T02:02:57.060811Z",
     "start_time": "2025-11-25T02:02:57.038477Z"
    }
   },
   "source": [
    "retriever=vectorstoredb.as_retriever()\n",
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain=create_retrieval_chain(retriever,document_chain)\n"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T02:03:04.194162Z",
     "start_time": "2025-11-25T02:03:04.176565Z"
    }
   },
   "source": [
    "retrieval_chain"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002CD52982260>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nAnswer the following question based only on the provided context:\\n<context>\\n{context}\\n</context>\\n\\n\\n'), additional_kwargs={})])\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000002CD52E743A0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002CD52E74460>, root_client=<openai.OpenAI object at 0x000002CD52E74340>, root_async_client=<openai.AsyncOpenAI object at 0x000002CD52E74850>, model_name='gpt-5-mini', model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://embedding-model-ai.openai.azure.com/openai/v1/')\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T02:05:29.360062Z",
     "start_time": "2025-11-25T02:05:20.300655Z"
    }
   },
   "source": [
    "## Get the response form the LLM\n",
    "response=retrieval_chain.invoke({\"input\":\"LangChain is the fastest way to build what ?\"})\n",
    "response['answer']"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Use LangChain when you want fast, high-level agent development; use LangGraph when you need fine-grained control for complex or sensitive workflows.\\n\\nQuick guidance (from the provided context)\\n- Choose LangChain 1.0 for:\\n  - Shipping quickly with standard agent patterns\\n  - Agents that fit the default loop (model → tools → response)\\n  - Middleware-based customization\\n  - Higher-level abstractions over low-level control\\n\\n- Choose LangGraph 1.0 for:\\n  - Workflows mixing deterministic and agentic components\\n  - Long‑running business process automation\\n  - Sensitive workflows requiring more oversight or human‑in‑the‑loop\\n  - Highly custom or complex workflows\\n\\nAdditional notes from the context\\n- LangChain agents are built on LangGraph, so you can start with LangChain and drop into LangGraph when you need more control.\\n- Graphs are composable: you can mix approaches (e.g., use agents created with create_agent inside custom LangGraph workflows).'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T02:06:02.120578Z",
     "start_time": "2025-11-25T02:06:02.102515Z"
    }
   },
   "source": [
    "\n",
    "response"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'LangChain is the fastest way to build what ?',\n",
       " 'context': [Document(id='5a533a25-a615-488f-b1be-f5e6bf684f6f', metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}, page_content=\"When to Use Each FrameworkLangChain lets you build and ship agents fast with high-level abstractions for common patterns, while LangGraph gives you fine-grained control for complex workflows that require customization.The best part? LangChain agents are built on LangGraph, so you're not locked in. Start with LangChain's high-level APIs and seamlessly drop down to LangGraph when you need more control. Since graphs are composable, you can mix both approaches—using agents created with create_agent inside custom LangGraph workflows as your needs evolve.Choose LangChain 1.0 for:Shipping quickly with standard agent patternsAgents that fit the default loop (model → tools → response)Middleware-based customizationHigher-level abstractions over low-level controlChoose LangGraph 1.0 for:Workflows with a mixture of deterministic and agentic componentsLong running business process automationSensitive workflows which necessitate more oversight / human in the loopHighly custom or complex\"),\n",
       "  Document(id='d6ffe952-82f0-4730-b17b-90ac88864893', metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}, page_content='LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCase Studies\\n\\n\\n\\n\\nIn the Loop\\n\\n\\n\\n\\nLangChain\\n\\n\\n\\n\\nDocs\\n\\n\\n\\n\\nChangelog\\n\\n\\n\\n\\n\\nSign in\\nSubscribe\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLangChain and LangGraph Agent Frameworks Reach v1.0 Milestones\\n\\n7 min read\\nOct 22, 2025'),\n",
       "  Document(id='d36c28e9-857d-4a96-8916-b03675c72e13', metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}, page_content=\"tested LangChain and LangGraph over the years to make them what they are today. With 90M monthly downloads and powering production applications at Uber, JP Morgan, Blackrock, Cisco, and more, we have a duty to you all to keep innovating but also be the most dependable framework for building agents. While this is a major milestone, we are still at the beginning of a major change in software. We want to hear from you: post on the LangChain Forum and tell us what you think of our 1.0 release and what you're building.\"),\n",
       "  Document(id='6ca8a10b-2074-42da-884d-788fb4e5b4fe', metadata={'source': 'https://blog.langchain.com/langchain-langgraph-1dot0/', 'title': 'LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones', 'language': 'en'}, page_content=\"changes until 2.0. Alongside these releases, we're launching a completely redesigned docs site.Learn more about the changes below, and check our behind-the-scenes conversation with our engineers for more commentary.LangChain 1.0LangChain has always offered high-level interfaces for interacting with LLMs and building agents. With standardized model abstractions and prebuilt agent patterns, it helps developers ship AI features fast and build sophisticated applications without vendor lock-in. This is essential in a space where the best model for any given task changes regularly.We've been listening. Over the past three years, we've heard consistent feedback: LangChain's abstractions were sometimes too heavy, the package surface area had grown unwieldy, and developers wanted more control over the agent loop without dropping down to raw LLM calls. Some struggled with customization when their use cases diverged from our prebuilt patterns. We took this feedback seriously. LangChain 1.0 is\")],\n",
       " 'answer': 'Use LangChain when you want fast, high-level agent development; use LangGraph when you need fine-grained control for complex or sensitive workflows.\\n\\nQuick guidance (from the provided context)\\n- Choose LangChain 1.0 for:\\n  - Shipping quickly with standard agent patterns\\n  - Agents that fit the default loop (model → tools → response)\\n  - Middleware-based customization\\n  - Higher-level abstractions over low-level control\\n\\n- Choose LangGraph 1.0 for:\\n  - Workflows mixing deterministic and agentic components\\n  - Long‑running business process automation\\n  - Sensitive workflows requiring more oversight or human‑in‑the‑loop\\n  - Highly custom or complex workflows\\n\\nAdditional notes from the context\\n- LangChain agents are built on LangGraph, so you can start with LangChain and drop into LangGraph when you need more control.\\n- Graphs are composable: you can mix approaches (e.g., use agents created with create_agent inside custom LangGraph workflows).'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='use usage limits to prevent future overspend.LangSmith has two usage limits: total traces and extended retention traces. These correspond to the two metrics we\\'ve\\nbeen tracking on our usage graph. We can use these in tandem to have granular control over spend.To set limits, we navigate back to Settings -> Usage and Billing -> Usage configuration. There is a table at the\\nbottom of the page that lets you set usage limits per workspace. For each workspace, the two limits appear, along\\nwith a cost estimate:Lets start by setting limits on our production usage, since that is where the majority of spend comes from.Setting a good total traces limit\\u200bPicking the right \"total traces\" limit depends on the expected load of traces that you will send to LangSmith. You should\\nclearly think about your assumptions before setting a limit.For example:Current Load: Our gen AI application is called between 1.2-1.5 times per second, and each API request has a trace associated with it,', metadata={'source': 'https://docs.smith.langchain.com/tutorials/Administrators/manage_spend', 'title': 'Optimize tracing spend on LangSmith | 🦜️🛠️ LangSmith', 'description': 'Before diving into this content, it might be helpful to read the following:', 'language': 'en'}),\n",
       " Document(page_content=\"more than 10% of traces.noteIf you want to keep a subset of traces for longer than 400 days for data collection purposes, you can create another run\\nrule that sends some runs to a dataset of your choosing. A dataset allows you to store the trace inputs and outputs (e.g., as a key-value dataset),\\nand will persist indefinitely, even after the trace gets deleted.See results after 7 days\\u200bWhile the total amount of traces per day stayed the same, the extended data retention traces was cut heavily.This translates to the invoice, where we've only spent about $900 in the last 7 days, as opposed to $2,000 in the previous 4.\\nThat's a cost reduction of nearly 75% per day!Optimization 2: limit usage\\u200bIn the previous section, we managed data retention settings to optimize existing spend. In this section, we will\\nuse usage limits to prevent future overspend.LangSmith has two usage limits: total traces and extended retention traces. These correspond to the two metrics we've\", metadata={'source': 'https://docs.smith.langchain.com/tutorials/Administrators/manage_spend', 'title': 'Optimize tracing spend on LangSmith | 🦜️🛠️ LangSmith', 'description': 'Before diving into this content, it might be helpful to read the following:', 'language': 'en'}),\n",
       " Document(page_content='and Invoices.Usage Graph\\u200bThe usage graph lets us examine how much of each usage based pricing metric we have consumed lately. It does not directly show\\nspend (which we will see later on our draft invoice).We can navigate to the Usage Graph under Settings -> Usage and Billing -> Usage Graph.We see in the graph above that there are two usage metrics that LangSmith charges for:LangSmith Traces (Base Charge)LangSmith Traces (Extended Data Retention Upgrades).The first metric tracks all traces that you send to LangSmith. The second tracks all traces that also have our Extended 400 Day Data Retention.\\nFor more details, see our data retention conceptual docs. Notice that these graphs look\\nidentical, which will come into play later in the tutorial.LangSmith Traces usage is measured per workspace, because workspaces often represent development environments (as in our example),', metadata={'source': 'https://docs.smith.langchain.com/tutorials/Administrators/manage_spend', 'title': 'Optimize tracing spend on LangSmith | 🦜️🛠️ LangSmith', 'description': 'Before diving into this content, it might be helpful to read the following:', 'language': 'en'}),\n",
       " Document(page_content='defaults for new projectsChange project level retention defaultsCOMING SOON Keep around a percentage of traces for extended data retentionSee results after 7 daysOptimization 2: limit usageSetting a good total traces limitCutting maximum spend with an extended data retention limitSet dev/staging limits and view total spent limit across workspacesSummaryCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.', metadata={'source': 'https://docs.smith.langchain.com/tutorials/Administrators/manage_spend', 'title': 'Optimize tracing spend on LangSmith | 🦜️🛠️ LangSmith', 'description': 'Before diving into this content, it might be helpful to read the following:', 'language': 'en'})]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['context']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
